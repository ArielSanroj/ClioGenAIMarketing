def extract_products(self, soup: BeautifulSoup, url: str) -> List[Dict]:
    """Extract products/services information with enhanced detection"""
    products = []
    
    # Common product container patterns
    product_containers = soup.find_all(class_=re.compile(r'product|service|item|card|offering|solution', re.I))
    if not product_containers:
        # Fallback to common HTML patterns
        product_containers = soup.find_all(['div', 'section', 'article'], 
            class_=re.compile(r'(?!header|footer|nav|menu)', re.I))
    
    for container in product_containers:
        try:
            # Extract product name
            name_element = (
                container.find(['h1', 'h2', 'h3', 'h4', 'strong'], class_=re.compile(r'title|name|heading', re.I)) or
                container.find(['h1', 'h2', 'h3', 'h4', 'strong'])
            )
            if not name_element:
                continue
            
            name = name_element.get_text().strip()
            if not name or name.lower() in ['menu', 'navigation', 'footer']:
                continue
                
            # Extract description
            description_element = (
                container.find(['p', 'div'], class_=re.compile(r'description|details|content|text', re.I)) or
                container.find(['p', 'div'])
            )
            description = description_element.get_text().strip() if description_element else ""
            
            # Extract price
            price = None
            price_patterns = [
                r'\$\s*(\d+(?:,\d{3})*(?:\.\d{2})?)',  # Standard price format
                r'(\d+(?:,\d{3})*(?:\.\d{2})?)\s*USD',  # USD format
                r'starting at\s*\$\s*(\d+(?:,\d{3})*(?:\.\d{2})?)',  # Starting at format
                r'from\s*\$\s*(\d+(?:,\d{3})*(?:\.\d{2})?)'  # From format
            ]
            
            for pattern in price_patterns:
                price_match = re.search(pattern, container.get_text(), re.I)
                if price_match:
                    price = price_match.group(1)
                    break
            
            # Extract image
            image = container.find('img')
            image_url = None
            if image:
                src = image.get('src') or image.get('data-src') or image.get('data-lazy-src')
                if src:
                    image_url = urljoin(url, src)
            
            # Extract features/specifications
            features = []
            feature_lists = container.find_all(['ul', 'ol'])
            for feature_list in feature_lists:
                features.extend([item.get_text().strip() for item in feature_list.find_all('li')])
            
            # Extract call-to-action links
            cta = None
            cta_element = container.find('a', class_=re.compile(r'cta|button|learn-more|buy|purchase', re.I))
            if cta_element:
                cta = {
                    'text': cta_element.get_text().strip(),
                    'url': urljoin(url, cta_element['href'])
                }
            
            products.append({
                "name": name,
                "description": description,
                "price": price,
                "image_url": image_url,
                "features": features if features else None,
                "cta": cta
            })
            
        except Exception as e:
            continue
    
    # If no products found, try to find a dedicated products/services page
    if not products:
        products_link = soup.find('a', text=re.compile(r'products?|services?|solutions?', re.I))
        if products_link:
            products_url = urljoin(url, products_link['href'])
            try:
                response = requests.get(products_url, headers={'User-Agent': 'Mozilla/5.0'})
                new_soup = BeautifulSoup(response.text, 'html.parser')
                return self.extract_products(new_soup, products_url)
            except:
                pass
    
    return products[:10]  # Limit to 10 products for performance
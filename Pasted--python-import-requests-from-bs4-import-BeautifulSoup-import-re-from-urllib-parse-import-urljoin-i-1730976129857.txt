```python
import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import urljoin
import logging
from typing import Dict, List, Optional
from dataclasses import dataclass
import json
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

@dataclass
class Product:
    name: str
    description: str
    price: Optional[str]
    image_url: Optional[str]
    reviews: List[Dict]
    rating: Optional[float]

@dataclass
class CompanyInfo:
    name: str
    description: str
    products: List[Product]
    social_links: Dict[str, str]
    contact_info: Dict[str, str]
    reviews: List[Dict]
    images: List[str]

class UniversalWebScraper:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.setup_selenium()
        
    def setup_selenium(self):
        """Setup Selenium for dynamic content"""
        chrome_options = Options()
        chrome_options.add_argument("--headless")  # Run in headless mode
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        self.driver = webdriver.Chrome(options=chrome_options)

    def analyze_website(self, url: str) -> CompanyInfo:
        """Main function to analyze any company website"""
        try:
            self.driver.get(url)
            # Wait for dynamic content to load
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # Get the page source after JavaScript execution
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            company_info = CompanyInfo(
                name=self.extract_company_name(soup, url),
                description=self.extract_company_description(soup),
                products=self.extract_products(soup, url),
                social_links=self.extract_social_links(soup),
                contact_info=self.extract_contact_info(soup),
                reviews=self.extract_reviews(soup),
                images=self.extract_images(soup, url)
            )
            
            return company_info
            
        except Exception as e:
            self.logger.error(f"Error analyzing website {url}: {str(e)}")
            raise
        finally:
            self.driver.quit()

    def extract_company_name(self, soup: BeautifulSoup, url: str) -> str:
        """Extract company name from various possible locations"""
        # Try multiple common locations for company name
        possible_elements = [
            soup.find('meta', property='og:site_name'),
            soup.find('meta', property='og:title'),
            soup.find(['h1', 'h2'], class_=re.compile(r'logo|brand|company|header', re.I)),
            soup.find('title')
        ]
        
        for element in possible_elements:
            if element:
                name = element.get('content', element.text)
                if name and len(name) > 1:
                    return name.strip()
        
        # Fallback to domain name
        return url.split('/')[2].replace('www.', '').split('.')[0].capitalize()

    def extract_company_description(self, soup: BeautifulSoup) -> str:
        """Extract company description from various possible locations"""
        possible_elements = [
            soup.find('meta', {'name': 'description'}),
            soup.find('meta', property='og:description'),
            soup.find(class_=re.compile(r'about|description|company-info', re.I)),
            soup.find(['p', 'div'], class_=re.compile(r'intro|summary|mission', re.I))
        ]
        
        for element in possible_elements:
            if element:
                desc = element.get('content', element.text)
                if desc and len(desc) > 10:
                    return desc.strip()
        
        return "Description not found"

    def extract_products(self, soup: BeautifulSoup, base_url: str) -> List[Product]:
        """Extract product information"""
        products = []
        product_elements = soup.find_all(class_=re.compile(r'product|item|goods', re.I))
        
        if not product_elements:
            # Try finding products in common container patterns
            product_containers = soup.find_all(['div', 'article'], class_=re.compile(
                r'product|item|card|collection', re.I))
            
        for element in product_elements[:10]:  # Limit to first 10 products
            try:
                name = self.find_product_name(element)
                description = self.find_product_description(element)
                price = self.find_product_price(element)
                image_url = self.find_product_image(element, base_url)
                reviews = self.find_product_reviews(element)
                rating = self.find_product_rating(element)
                
                if name:  # Only add if we found at least a name
                    products.append(Product(
                        name=name,
                        description=description,
                        price=price,
                        image_url=image_url,
                        reviews=reviews,
                        rating=rating
                    ))
            except Exception as e:
                self.logger.warning(f"Error extracting product: {str(e)}")
                continue
                
        return products

    def find_product_name(self, element) -> Optional[str]:
        """Find product name within an element"""
        name_element = element.find(['h1', 'h2', 'h3', 'h4'], class_=re.compile(
            r'name|title|product-name', re.I))
        if name_element:
            return name_element.text.strip()
        return None

    def find_product_description(self, element) -> str:
        """Find product description within an element"""
        desc_element = element.find(class_=re.compile(r'description|details|info', re.I))
        return desc_element.text.strip() if desc_element else "No description available"

    def find_product_price(self, element) -> Optional[str]:
        """Find product price within an element"""
        price_element = element.find(class_=re.compile(r'price|cost|amount', re.I))
        if price_element:
            # Extract numbers and currency symbols
            price_text = price_element.text.strip()
            price_match = re.search(r'[\$\€\£]?\s*\d+(?:,\d{3})*(?:\.\d{2})?', price_text)
            return price_match.group(0) if price_match else None
        return None

    def find_product_image(self, element, base_url: str) -> Optional[str]:
        """Find product image URL within an element"""
        img_element = element.find('img')
        if img_element:
            src = img_element.get('src') or img_element.get('data-src')
            if src:
                return urljoin(base_url, src)
        return None

    def find_product_reviews(self, element) -> List[Dict]:
        """Find product reviews within an element"""
        reviews = []
        review_elements = element.find_all(class_=re.compile(r'review|comment', re.I))
        
        for review in review_elements[:5]:  # Limit to 5 reviews per product
            author = review.find(class_=re.compile(r'author|name', re.I))
            text = review.find(class_=re.compile(r'text|content', re.I))
            if text:
                reviews.append({
                    'author': author.text.strip() if author else 'Anonymous',
                    'text': text.text.strip()
                })
        return reviews

    def find_product_rating(self, element) -> Optional[float]:
        """Find product rating within an element"""
        rating_element = element.find(class_=re.compile(r'rating|stars', re.I))
        if rating_element:
            # Try to extract numeric rating
            rating_text = rating_element.text.strip()
            rating_match = re.search(r'\d+(?:\.\d+)?', rating_text)
            if rating_match:
                return float(rating_match.group(0))
        return None

    def extract_social_links(self, soup: BeautifulSoup) -> Dict[str, str]:
        """Extract social media links"""
        social_platforms = {
            'facebook': r'facebook\.com',
            'twitter': r'twitter\.com',
            'instagram': r'instagram\.com',
            'linkedin': r'linkedin\.com',
            'youtube': r'youtube\.com'
        }
        
        social_links = {}
        for platform, pattern in social_platforms.items():
            social_link = soup.find('a', href=re.compile(pattern))
            if social_link:
                social_links[platform] = social_link['href']
                
        return social_links

    def extract_contact_info(self, soup: BeautifulSoup) -> Dict[str, str]:
        """Extract contact information"""
        contact_info = {}
        
        # Extract email
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        email_element = soup.find(text=re.compile(email_pattern))
        if email_element:
            contact_info['email'] = re.search(email_pattern, email_element).group(0)
        
        # Extract phone
        phone_pattern = r'[\+]?[(]?[0-9]{3}[)]?[-\s\.]?[0-9]{3}[-\s\.]?[0-9]{4,6}'
        phone_element = soup.find(text=re.compile(phone_pattern))
        if phone_element:
            contact_info['phone'] = re.search(phone_pattern, phone_element).group(0)
        
        # Extract address
        address_element = soup.find(class_=re.compile(r'address|location', re.I))
        if address_element:
            contact_info['address'] = address_element.text.strip()
            
        return contact_info

    def extract_reviews(self, soup: BeautifulSoup) -> List[Dict]:
        """Extract customer reviews"""
        reviews = []
        review_elements = soup.find_all(class_=re.compile(r'review|testimonial|comment', re.I))
        
        for review in review_elements[:10]:  # Limit to 10 reviews
            author = review.find(class_=re.compile(r'author|name|user', re.I))
            text = review.find(class_=re.compile(r'text|content|description', re.I))
            rating = review.find(class_=re.compile(r'rating|stars', re.I))
            
            if text:
                reviews.append({
                    'author': author.text.strip() if author else 'Anonymous',
                    'text': text.text.strip(),
                    'rating': float(re.search(r'\d+(?:\.\d+)?', rating.text).group(0)) if rating else None
                })
                
        return reviews

    def extract_images(self, soup: BeautifulSoup, base_url: str) -> List[str]:
        """Extract relevant images"""
        images = []
        img_elements = soup.find_all('img')
        
        for img in img_elements:
            src = img.get('src') or img.get('data-src')
            if src:
                # Filter out small icons and logos
                if not re.search(r'icon|logo|small', src, re.I):
                    full_url = urljoin(base_url, src)
                    images.append(full_url)
                    
        return images[:20]  # Limit to 20 images

```

Key features of this enhanced scraper:

1. Universal Compatibility:
- Handles different website structures
- Multiple fallback methods for each data point
- Flexible pattern matching

2. Comprehensive Data Extraction:
- Company information
- Product details
- Pricing
- Reviews and ratings
- Images
- Contact information
- Social media links

3. Advanced Features:
- Dynamic content handling with Selenium
- Image URL resolution
- Price format standardization
- Review aggregation
- Rating extraction

4. Robust Error Handling:
- Graceful fallbacks
- Detailed logging
- Exception management
- Data validation

To use this scraper:

```python
scraper = UniversalWebScraper()
company_info = scraper.analyze_website("https://example.com")
print(json.dumps(company_info.__dict__, indent=2))
```

Would you like me to:
1. Add more specific industry detection?
2. Enhance product categorization?
3. Add sentiment analysis for reviews?
4. Implement competitor analysis?